# Техническое видение проекта

## 1. Технологии

### Core
- **Python 3.11+** - используется установленная версия
- **uv** - управление зависимостями и виртуальным окружением

### Основные библиотеки
- **aiogram 3.x** - фреймворк для Telegram Bot API (polling)
- **openai** - клиент для работы с LLM через OpenRouter
- **python-dotenv** - управление конфигурацией

### Инструменты разработки
- **make** - автоматизация команд
- **ruff** - быстрый линтер и форматтер

---

## 2. Принципы разработки

### Ключевые принципы
- **KISS** - максимальная простота решений
- **ООП** - 1 класс = 1 файл
- **MVP-подход** - только необходимый функционал
- **Читаемость кода** превыше оптимизаций

### Правила кодирования
- Один класс в одном файле
- Docstrings для классов и публичных методов
- Понятные имена переменных и функций
- Минимальная вложенность (2-3 уровня)
- Никаких абстракций "на будущее"

### Разработка
- Тесты пишем после проверки концепции

---

## 3. Структура проекта

```
systech-aidd-test/
├── docs/                  # Документация
│   ├── IDEA.md
│   └── VISION.md
├── src/                   # Исходный код
│   ├── __init__.py
│   ├── main.py           # Точка входа
│   ├── bot.py            # TelegramBot класс
│   ├── llm_client.py     # LLMClient класс
│   ├── config.py         # Config класс
│   └── logger.py         # Logger настройка
├── logs/                  # Логи
├── .env.example          # Пример конфигурации
├── .env                  # Конфигурация
├── .gitignore
├── Makefile              # Команды управления
├── pyproject.toml        # Конфигурация uv
└── README.md             # Инструкция
```

---

## 4. Архитектура проекта

### Компоненты системы

1. **TelegramBot** - обработка сообщений Telegram
2. **LLMClient** - взаимодействие с OpenRouter API
3. **Config** - управление конфигурацией
4. **Logger** - логирование событий

### Поток данных

```
Пользователь → Telegram → TelegramBot → LLMClient → OpenRouter (LLM)
                                ↓                          ↓
                         Ответ пользователю ← TelegramBot ← Ответ LLM
```

### Управление контекстом
- История диалога хранится в памяти (на время работы бота)
- Контекст: последние 20 сообщений на пользователя

---

## 5. Модель данных

### Конфигурация (dict)

```python
{
    "telegram_token": str,
    "openrouter_api_key": str,
    "openrouter_model": str,
    "system_prompt": str,
    "log_file_path": str,
    "max_context_messages": int
}
```

### История диалога (in-memory dict)

```python
{
    user_id: [
        {"role": "user", "content": "сообщение пользователя"},
        {"role": "assistant", "content": "ответ бота"}
    ]
}
```

---

## 6. Работа с LLM

### LLMClient реализация

1. **Инициализация:**
   - Асинхронный OpenAI клиент с base_url для OpenRouter
   - Системный промпт из конфига

2. **Формирование запроса:**
   - Структура: system prompt + последние 20 сообщений + новое сообщение
   - Формат OpenAI API: `[{"role": "system/user/assistant", "content": "..."}]`

3. **Вызов API:**
   - Асинхронный метод `await chat.completions.create()`
   - Параметры модели: по умолчанию (temperature, max_tokens)

4. **Обработка:**
   - Извлечение текста ответа
   - Логирование запросов/ответов
   - Обработка ошибок API

---

## 7. Сценарии работы

### Основные команды

- `/start` - приветствие и описание возможностей бота
- `/help` - список доступных команд
- `/reset` - очистка истории диалога
- `/status` - проверка работоспособности бота

### Сценарий общения

1. Пользователь отправляет сообщение
2. Бот показывает статус "печатает..." (typing action)
3. Бот отправляет запрос в LLM с контекстом (последние 20 сообщений)
4. Бот возвращает ответ пользователю

### Обработка ошибок

- Технические ошибки логируются в файл
- Пользователю показываются дружественные сообщения

---

## 8. Подход к конфигурированию

### Файл .env

```ini
# Telegram Bot
TELEGRAM_BOT_TOKEN=your_token_here

# OpenRouter API
OPENROUTER_API_KEY=your_key_here
OPENROUTER_MODEL=anthropic/claude-3.5-sonnet
OPENROUTER_BASE_URL=https://openrouter.ai/api/v1

# LLM Settings
SYSTEM_PROMPT=Ты - полезный AI-ассистент. Отвечай кратко и по делу.
MAX_CONTEXT_MESSAGES=20

# Logging
LOG_FILE_PATH=logs/bot.log
LOG_LEVEL=INFO
```

### Принципы

- Загрузка через `python-dotenv`
- Значения по умолчанию для необязательных параметров
- Валидация при старте с предупреждениями об отсутствующих параметрах
- Класс Config с методом `load()` возвращающий dict

---

## 9. Подход к логированию

### Настройка

- Стандартный модуль `logging`
- Вывод в файл `logs/bot.log` и консоль
- Ротация: по умолчанию (без настройки для MVP)
- Формат: `%(asctime)s - %(name)s - %(levelname)s - %(message)s`

### Уровни

- `INFO` - старт/остановка, команды, сообщения
- `WARNING` - нештатные ситуации
- `ERROR` - ошибки API, исключения
- Уровень из конфига: `LOG_LEVEL`

### Что логируем

- Запуск/остановка бота
- Команды: `user_id`, команда
- Сообщения: `user_id`, первые 200 символов, длина
- Запросы/ответы LLM (сокращенно)
- Ошибки с stack trace

---

## Итого

Проект представляет собой **простое и понятное MVP-решение** для проверки идеи LLM-ассистента в Telegram. Следуя принципам KISS и ООП, мы создаем минимально необходимую функциональность без оверинжиниринга, с возможностью быстрой итерации и улучшения после проверки концепции.

