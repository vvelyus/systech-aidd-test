"""–°–µ—Ä–≤–∏—Å –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ —á–∞—Ç-—Å–æ–æ–±—â–µ–Ω–∏–π —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π streaming."""

import asyncio
import logging
import time
import uuid
from typing import TYPE_CHECKING, AsyncGenerator

from sqlalchemy import select
from sqlalchemy.ext.asyncio import AsyncSession

from src.api.models import ChatMode, ChatMessage as ChatMessageModel, MessageRole
from src.models import ChatMessage as ChatMessageDB, ChatSession as ChatSessionDB
from src.text2sql import Text2SqlConverter
from src.llm_client import RateLimitExceededError

if TYPE_CHECKING:
    from src.llm_client import LLMClient
    from src.database import DatabaseManager


# –°–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ system prompts –¥–ª—è —Ä–∞–∑–Ω—ã—Ö —Ä–µ–∂–∏–º–æ–≤
SYSTEM_PROMPTS = {
    "normal": """You are a helpful AI assistant. Your role is to:
1. Answer questions accurately and comprehensively
2. Provide context-aware responses based on conversation history
3. Ask clarifying questions if needed
4. Be concise but informative
5. Maintain conversation context across multiple messages

Be friendly and professional in your responses.""",

    "admin": """You are a SQL expert and data analyst assistant. Your role is to:
1. Analyze dialog statistics from the database
2. Provide insights based on SQL query results
3. Answer questions about user engagement, message patterns, and trends
4. Format results clearly and concisely
5. Suggest relevant follow-up queries

Be precise and fact-based in your responses."""
}


class ChatService:
    """–°–µ—Ä–≤–∏—Å –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Å–æ–æ–±—â–µ–Ω–∏–π —á–∞—Ç–∞ –≤ –æ–±–æ–∏—Ö —Ä–µ–∂–∏–º–∞—Ö."""

    def __init__(
        self,
        llm_client: "LLMClient",
        db_manager: "DatabaseManager",
        logger: logging.Logger,
        chunk_size: int = 50,
        request_timeout: float = 30.0,
        text2sql_timeout: float = 5.0,
    ) -> None:
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å–µ—Ä–≤–∏—Å–∞.

        Args:
            llm_client: –ö–ª–∏–µ–Ω—Ç –¥–ª—è LLM
            db_manager: –ú–µ–Ω–µ–¥–∂–µ—Ä –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö
            logger: –õ–æ–≥–≥–µ—Ä
            chunk_size: –†–∞–∑–º–µ—Ä chunk'–∞ –¥–ª—è streaming (–∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–∏–º–≤–æ–ª–æ–≤)
            request_timeout: –¢–∞–π–º–∞—É—Ç –¥–ª—è LLM request –≤ —Å–µ–∫—É–Ω–¥–∞—Ö (default 30s)
            text2sql_timeout: –¢–∞–π–º–∞—É—Ç –¥–ª—è Text-to-SQL –≤ —Å–µ–∫—É–Ω–¥–∞—Ö (default 5s)
        """
        self.llm_client = llm_client
        self.db_manager = db_manager
        self.logger = logger
        self.text2sql = Text2SqlConverter(llm_client, db_manager, logger)
        self.chunk_size = chunk_size
        self.request_timeout = request_timeout
        self.text2sql_timeout = text2sql_timeout

        # Temperature config per mode
        self.temperature_config = {
            ChatMode.NORMAL: 0.7,  # Higher for more conversational, creative responses
            ChatMode.ADMIN: 0.3,   # Lower for more factual, deterministic SQL responses
        }

        self.logger.info(
            f"ChatService initialized with timeouts: "
            f"request={request_timeout}s, text2sql={text2sql_timeout}s"
        )

    async def process_message(
        self,
        message: str,
        session_id: str,
        mode: ChatMode = ChatMode.NORMAL,
        context_storage=None,
        max_retries: int = 3,
    ) -> AsyncGenerator[str, None]:
        """
        –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç —Å–æ–æ–±—â–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç streaming –æ—Ç–≤–µ—Ç.

        Args:
            message: –°–æ–æ–±—â–µ–Ω–∏–µ –æ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            session_id: ID —Å–µ—Å—Å–∏–∏ —á–∞—Ç–∞
            mode: –†–µ–∂–∏–º —á–∞—Ç–∞ (normal –∏–ª–∏ admin)
            context_storage: –•—Ä–∞–Ω–∏–ª–∏—â–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –¥–ª—è –æ–±—ã—á–Ω–æ–≥–æ —Ä–µ–∂–∏–º–∞
            max_retries: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ–ø—ã—Ç–æ–∫ –ø—Ä–∏ –æ—à–∏–±–∫–µ

        Yields:
            –ß–∞—Å—Ç–∏ –æ—Ç–≤–µ—Ç–∞ –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞
        """
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        user_msg_id = str(uuid.uuid4())
        user_message = ChatMessageDB(
            id=user_msg_id,
            user_session_id=session_id,
            content=message,
            role=MessageRole.USER.value,
            mode=mode.value,
        )
        await self.save_message(user_message)

        try:
            if mode == ChatMode.ADMIN:
                # –ê–¥–º–∏–Ω —Ä–µ–∂–∏–º: Text-to-SQL pipeline —Å retry logic
                async for chunk in self._process_admin_mode_with_retry(
                    message, session_id, max_retries
                ):
                    yield chunk
            else:
                # –û–±—ã—á–Ω—ã–π —Ä–µ–∂–∏–º: LLM –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç —Å retry logic
                async for chunk in self._process_normal_mode_with_retry(
                    message, session_id, context_storage, max_retries
                ):
                    yield chunk

        except RateLimitExceededError as e:
            # –°–ø–µ—Ü–∏–∞–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–ª—è rate limit –æ—à–∏–±–æ–∫
            self.logger.error(f"Rate limit in chat service: {e}")

            # –§–æ—Ä–º–∏—Ä—É–µ–º –¥—Ä—É–∂–µ—Å—Ç–≤–µ–Ω–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –Ω–∞ —Ä—É—Å—Å–∫–æ–º
            error_message = (
                "–õ–∏–º–∏—Ç –±–µ—Å–ø–ª–∞—Ç–Ω–æ–≥–æ –ø–ª–∞–Ω–∞ –∏—Å—á–µ—Ä–ø–∞–Ω\n"
                "–î–Ω–µ–≤–Ω–æ–π –ª–∏–º–∏—Ç –Ω–∞ –±–µ—Å–ø–ª–∞—Ç–Ω–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –¥–æ—Å—Ç–∏–≥–Ω—É—Ç.\n\n"
                "–ß—Ç–æ –¥–µ–ª–∞—Ç—å:\n"
                "1. –î–æ–±–∞–≤—å—Ç–µ –∫—Ä–µ–¥–∏—Ç—ã –Ω–∞ https://openrouter.ai/account/billing\n"
                "2. –î–æ–∂–¥–∏—Ç–µ—Å—å –∑–∞–≤—Ç—Ä–∞ (00:00 UTC) - –ª–∏–º–∏—Ç —Å–±—Ä–æ—Å–∏—Ç—Å—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏\n"
                "3. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –±–æ–ª–µ–µ –ø—Ä–æ—Å—Ç—ã–µ –∑–∞–ø—Ä–æ—Å—ã\n\n"
                "–ü–æ—á–µ–º—É —Ç–∞–∫ –ø—Ä–æ–∏—Å—Ö–æ–¥–∏—Ç: –ë–µ—Å–ø–ª–∞—Ç–Ω—ã–π –ø–ª–∞–Ω –æ–≥—Ä–∞–Ω–∏—á–µ–Ω –ø—Ä–∏–º–µ—Ä–Ω–æ 30-50 –∑–∞–ø—Ä–æ—Å–∞–º–∏ –≤ –¥–µ–Ω—å. –ü–µ—Ä–µ–π–¥–∏—Ç–µ –Ω–∞ –ø–ª–∞—Ç–Ω—ã–π –ø–ª–∞–Ω –¥–ª—è –Ω–µ–æ–≥—Ä–∞–Ω–∏—á–µ–Ω–Ω–æ–≥–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è."
            )
            yield error_message

            # Save error message to history
            error_msg = ChatMessageDB(
                id=str(uuid.uuid4()),
                user_session_id=session_id,
                content=error_message,
                role=MessageRole.ASSISTANT.value,
                mode=mode.value,
            )
            await self.save_message(error_msg)

        except Exception as e:
            self.logger.error(f"Error processing message in {mode.value} mode: {e}")
            error_message = (
                f"Error processing your request: {str(e)[:100]}. "
                "Please try again with a simpler question."
            )
            yield error_message

            # Save error message to history
            error_msg = ChatMessageDB(
                id=str(uuid.uuid4()),
                user_session_id=session_id,
                content=error_message,
                role=MessageRole.ASSISTANT.value,
                mode=mode.value,
            )
            await self.save_message(error_msg)

    async def _process_normal_mode_with_retry(
        self,
        message: str,
        session_id: str,
        context_storage,
        max_retries: int,
    ) -> AsyncGenerator[str, None]:
        """Process normal mode with retry logic."""
        for attempt in range(max_retries):
            try:
                async for chunk in self._process_normal_mode(
                    message, session_id, context_storage
                ):
                    yield chunk
                return
            except RateLimitExceededError:
                # Don't retry for rate limits, just raise immediately
                self.logger.error(f"Rate limit error - no retry for rate limits")
                raise
            except asyncio.TimeoutError:
                self.logger.warning(f"Normal mode timeout on attempt {attempt + 1}")
                if attempt < max_retries - 1:
                    await asyncio.sleep(0.5 * (attempt + 1))  # Exponential backoff
                    continue
                raise
            except Exception as e:
                self.logger.error(f"Normal mode error on attempt {attempt + 1}: {e}")
                if attempt < max_retries - 1:
                    await asyncio.sleep(0.5 * (attempt + 1))
                    continue
                raise

    async def _process_admin_mode_with_retry(
        self,
        message: str,
        session_id: str,
        max_retries: int,
    ) -> AsyncGenerator[str, None]:
        """Process admin mode with retry logic."""
        for attempt in range(max_retries):
            try:
                async for chunk in self._process_admin_mode(message, session_id):
                    yield chunk
                return
            except RateLimitExceededError:
                # Don't retry for rate limits, just raise immediately
                self.logger.error(f"Rate limit error - no retry for rate limits")
                raise
            except asyncio.TimeoutError:
                self.logger.warning(f"Admin mode timeout on attempt {attempt + 1}")
                if attempt < max_retries - 1:
                    await asyncio.sleep(0.5 * (attempt + 1))  # Exponential backoff
                    continue
                raise
            except Exception as e:
                self.logger.error(f"Admin mode error on attempt {attempt + 1}: {e}")
                if attempt < max_retries - 1:
                    await asyncio.sleep(0.5 * (attempt + 1))
                    continue
                raise

    def _optimize_streaming_chunks(self, text: str) -> list[str]:
        """
        –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å chunks –¥–ª—è streaming.

        –í—ã–±—Ä–∞—Ç—å —Ç–æ—á–∫–∏ —Ä–∞–∑–±–∏–µ–Ω–∏—è:
        - –ü–æ—Å–ª–µ –∫–∞–∂–¥—ã—Ö ~chunk_size —Å–∏–º–≤–æ–ª–æ–≤
        - –ù–∞ –≥—Ä–∞–Ω–∏—Ü–∞—Ö –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π (. ! ? ;)
        - –ü–æ—Å–ª–µ –∑–∞–ø—è—Ç—ã—Ö –∏ –¥–≤–æ–µ—Ç–æ—á–∏–π –¥–ª—è –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ —Ä–∞–∑–±–∏–µ–Ω–∏—è
        """
        chunks = []
        current_chunk = ""

        for i, char in enumerate(text):
            current_chunk += char

            # Check if we should split
            should_split = False
            if len(current_chunk) >= self.chunk_size:
                # Look for natural break points
                if char in ".!?;":
                    should_split = True
                elif char == "," and len(current_chunk) >= self.chunk_size * 0.8:
                    should_split = True
                elif i == len(text) - 1:  # Last character
                    should_split = True
            elif i == len(text) - 1:  # Last character
                should_split = True

            if should_split and current_chunk.strip():
                chunks.append(current_chunk)
                current_chunk = ""

        return chunks if chunks else [text]

    async def _process_normal_mode(
        self,
        message: str,
        session_id: str,
        context_storage=None,
    ) -> AsyncGenerator[str, None]:
        """
        –û–±—Ä–∞–±–æ—Ç–∞—Ç—å —Å–æ–æ–±—â–µ–Ω–∏–µ –≤ –æ–±—ã—á–Ω–æ–º —Ä–µ–∂–∏–º–µ (LLM assistant).

        –ó–∞–≥—Ä—É–∂–∞–µ—Ç –∏—Å—Ç–æ—Ä–∏—é —Å–æ–æ–±—â–µ–Ω–∏–π –∏–∑ –ë–î –∏ –ø–µ—Ä–µ–¥–∞–µ—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç –≤ LLM,
        —á—Ç–æ–±—ã –±–æ—Ç –ø–æ–º–Ω–∏–ª –ø—Ä–µ–¥—ã–¥—É—â–∏–µ —Ä–∞–∑–≥–æ–≤–æ—Ä—ã.
        """
        # –î–æ–±–∞–≤–∏—Ç—å —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π system prompt –¥–ª—è normal —Ä–µ–∂–∏–º–∞
        system_prompt = SYSTEM_PROMPTS["normal"]
        temperature = self.temperature_config[ChatMode.NORMAL]

        # Get response from LLM with timeout
        try:
            # üëá –ù–û–í–û–ï: –ó–∞–≥—Ä—É–∂–∞–µ–º –∏—Å—Ç–æ—Ä–∏—é —Å–æ–æ–±—â–µ–Ω–∏–π –∏–∑ –ë–î –¥–ª—è —ç—Ç–æ–π —Å–µ—Å—Å–∏–∏
            history = await self.get_history(session_id, limit=20)

            # –§–æ—Ä–º–∏—Ä—É–µ–º messages –¥–ª—è LLM —Å –∏—Å—Ç–æ—Ä–∏–µ–π
            messages = [
                {"role": "system", "content": system_prompt}
            ]

            # –î–æ–±–∞–≤–ª—è–µ–º –ø—Ä–µ–¥—ã–¥—É—â–∏–µ —Å–æ–æ–±—â–µ–Ω–∏—è –∏–∑ –∏—Å—Ç–æ—Ä–∏–∏
            for hist_msg in history:
                messages.append({
                    "role": hist_msg.role,
                    "content": hist_msg.content
                })

            # –î–æ–±–∞–≤–ª—è–µ–º —Ç–µ–∫—É—â–µ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            messages.append({
                "role": "user",
                "content": message
            })

            self.logger.info(
                f"Processing message in normal mode with {len(history)} history messages. "
                f"Session: {session_id}"
            )

            # –í—ã–∑—ã–≤–∞–µ–º LLM —Å –ø–æ–ª–Ω—ã–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º (–Ω–∞–ø—Ä—è–º—É—é, –Ω–µ —á–µ—Ä–µ–∑ context_storage)
            full_response = ""
            response = await asyncio.wait_for(
                self._call_llm_with_messages(messages),
                timeout=self.request_timeout
            )

            # –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å chunks –¥–ª—è streaming
            chunks = self._optimize_streaming_chunks(response)

            for chunk in chunks:
                full_response += chunk
                yield chunk

            # –°–æ—Ö—Ä–∞–Ω–∏—Ç—å –æ—Ç–≤–µ—Ç –≤ –ë–î
            assistant_msg = ChatMessageDB(
                id=str(uuid.uuid4()),
                user_session_id=session_id,
                content=full_response,
                role=MessageRole.ASSISTANT.value,
                mode=ChatMode.NORMAL.value,
            )
            await self.save_message(assistant_msg)

        except asyncio.TimeoutError:
            self.logger.error(f"LLM timeout after {self.request_timeout}s")
            yield f"Sorry, the response took too long ({self.request_timeout}s). Please try with a simpler question."

    async def _call_llm_with_messages(self, messages: list[dict]) -> str:
        """
        –í—ã–∑–≤–∞—Ç—å LLM –Ω–∞–ø—Ä—è–º—É—é —Å –º–∞—Å—Å–∏–≤–æ–º messages.

        Args:
            messages: –ú–∞—Å—Å–∏–≤ —Å–æ–æ–±—â–µ–Ω–∏–π –≤ —Ñ–æ—Ä–º–∞—Ç–µ [{"role": "...", "content": "..."}, ...]

        Returns:
            –û—Ç–≤–µ—Ç –æ—Ç LLM
        """
        try:
            response = await self.llm_client._api_call_with_retry(messages)
            return response
        except Exception as e:
            self.logger.error(f"Error calling LLM: {e}")
            raise

    async def _process_admin_mode(
        self,
        message: str,
        session_id: str,
    ) -> AsyncGenerator[str, None]:
        """
        –û–±—Ä–∞–±–æ—Ç–∞—Ç—å —Å–æ–æ–±—â–µ–Ω–∏–µ –≤ –∞–¥–º–∏–Ω —Ä–µ–∂–∏–º–µ (Text-to-SQL + LLM).
        """
        system_prompt = SYSTEM_PROMPTS["admin"]
        temperature = self.temperature_config[ChatMode.ADMIN]

        try:
            # –≠—Ç–∞–ø 1: Text-to-SQL –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è —Å timeout
            text2sql_response = await asyncio.wait_for(
                self.text2sql.convert(message, max_retries=3),
                timeout=self.text2sql_timeout
            )

            if not text2sql_response.sql:
                error_msg = (
                    f"Could not generate SQL: {text2sql_response.error or 'Unknown error'}. "
                    "Please try with a different question."
                )
                yield error_msg
                return

            # Yield the SQL query for debugging
            yield f"SQL Query: {text2sql_response.sql}\n\n"

            # –≠—Ç–∞–ø 2: –í—ã–ø–æ–ª–Ω–∏—Ç—å SQL –∏ –ø–æ–ª—É—á–∏—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
            results = await asyncio.wait_for(
                self.text2sql.execute_and_format(
                    text2sql_response.sql,
                    max_rows=1000,
                    timeout=10.0
                ),
                timeout=20.0
            )

            # –≠—Ç–∞–ø 3: –û—Ç–ø—Ä–∞–≤–∏—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ LLM –¥–ª—è –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏–∏
            llm_prompt = f"""Based on the following SQL query results, provide a concise analysis and answer the user's question.

SQL Query: {text2sql_response.sql}

Results:
{results}

User Question: {message}

Provide a clear, factual answer based on the data."""

            full_response = ""
            llm_response = await asyncio.wait_for(
                self.llm_client.get_response(llm_prompt),
                timeout=self.request_timeout
            )

            # –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å chunks –¥–ª—è streaming
            chunks = self._optimize_streaming_chunks(llm_response)

            for chunk in chunks:
                full_response += chunk
                yield chunk

            # –°–æ—Ö—Ä–∞–Ω–∏—Ç—å –ø–æ–ª–Ω—ã–π –æ—Ç–≤–µ—Ç –≤ –ë–î (—Å SQL –∑–∞–ø—Ä–æ—Å–æ–º)
            assistant_msg = ChatMessageDB(
                id=str(uuid.uuid4()),
                user_session_id=session_id,
                content=full_response,
                role=MessageRole.ASSISTANT.value,
                mode=ChatMode.ADMIN.value,
                sql_query=text2sql_response.sql,  # Save SQL for debugging
            )
            await self.save_message(assistant_msg)

        except asyncio.TimeoutError as e:
            error_msg = (
                f"Request timed out (too complex query). "
                "Please try with a simpler question."
            )
            yield error_msg
        except Exception as e:
            self.logger.error(f"Error in admin mode: {e}")
            yield f"Error processing your request: {str(e)[:100]}"

    async def save_message(self, message: ChatMessageDB) -> None:
        """
        –°–æ—Ö—Ä–∞–Ω—è–µ—Ç —Å–æ–æ–±—â–µ–Ω–∏–µ –≤ –ë–î.

        Args:
            message: –°–æ–æ–±—â–µ–Ω–∏–µ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è
        """
        try:
            session = self.db_manager.create_session()
            session.add(message)
            await session.commit()
            self.logger.debug(f"Message saved: {message.id}")
        except Exception as e:
            self.logger.error(f"Error saving message: {e}")
            raise

    async def get_history(
        self, session_id: str, limit: int = 50
    ) -> list[ChatMessageModel]:
        """
        –ü–æ–ª—É—á–∞–µ—Ç –∏—Å—Ç–æ—Ä–∏—é —Å–æ–æ–±—â–µ–Ω–∏–π –¥–ª—è —Å–µ—Å—Å–∏–∏.

        Args:
            session_id: ID —Å–µ—Å—Å–∏–∏
            limit: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–æ–æ–±—â–µ–Ω–∏–π

        Returns:
            –°–ø–∏—Å–æ–∫ —Å–æ–æ–±—â–µ–Ω–∏–π –∏–∑ –ë–î
        """
        try:
            session = self.db_manager.create_session()
            stmt = (
                select(ChatMessageDB)
                .where(ChatMessageDB.user_session_id == session_id)
                .order_by(ChatMessageDB.created_at.asc())
                .limit(limit)
            )
            result = await session.execute(stmt)
            messages = result.scalars().all()

            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ Pydantic –º–æ–¥–µ–ª–∏
            return [
                ChatMessageModel(
                    id=msg.id,
                    user_session_id=msg.user_session_id,
                    content=msg.content,
                    role=msg.role,
                    mode=msg.mode,
                    sql_query=msg.sql_query,
                    created_at=msg.created_at.isoformat(),
                )
                for msg in messages
            ]

        except Exception as e:
            self.logger.error(f"Error getting history: {e}")
            return []

    async def create_session(
        self, user_id: int, mode: ChatMode = ChatMode.NORMAL
    ) -> str:
        """
        –°–æ–∑–¥–∞–µ—Ç –Ω–æ–≤—É—é —Å–µ—Å—Å–∏—é —á–∞—Ç–∞.

        Args:
            user_id: ID –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            mode: –†–µ–∂–∏–º —á–∞—Ç–∞

        Returns:
            ID –Ω–æ–≤–æ–π —Å–µ—Å—Å–∏–∏
        """
        try:
            session_id = str(uuid.uuid4())
            session = ChatSessionDB(
                id=session_id,
                user_id=user_id,
                mode=mode.value,
            )

            db_session = self.db_manager.create_session()
            db_session.add(session)
            await db_session.commit()
            self.logger.info(f"Chat session created: {session_id} for user {user_id}")
            return session_id

        except Exception as e:
            self.logger.error(f"Error creating session: {e}")
            raise

    async def get_session(self, session_id: str) -> ChatSessionDB | None:
        """
        –ü–æ–ª—É—á–∞–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Å–µ—Å—Å–∏–∏.

        Args:
            session_id: ID —Å–µ—Å—Å–∏–∏

        Returns:
            –û–±—ä–µ–∫—Ç —Å–µ—Å—Å–∏–∏ –∏–ª–∏ None
        """
        try:
            db_session = self.db_manager.create_session()
            stmt = select(ChatSessionDB).where(ChatSessionDB.id == session_id)
            result = await db_session.execute(stmt)
            return result.scalars().first()

        except Exception as e:
            self.logger.error(f"Error getting session: {e}")
            return None
